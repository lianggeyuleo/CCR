{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177bbda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import tqdm\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from joblib import Parallel, delayed, cpu_count, dump, load\n",
    "import random\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset name is a value from the set {\"imagenet\", \"places365\", \"cub\", \"cifar10\", \"cifar100\"}\n",
    "dataset = 'cifar10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29decf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_project(dictionary, init_dictionary, r):\n",
    "    dictionary = dictionary / torch.norm(dictionary, p=2, dim=1, keepdim=True)\n",
    "    diff = dictionary - init_dictionary\n",
    "    diff_length = torch.norm(diff, p=2, dim=1, keepdim=True)\n",
    "    idx = torch.nonzero(diff_length.squeeze() > r).squeeze()\n",
    "    diff_dir = diff / diff_length\n",
    "    diff[idx] = diff_dir[idx] * r\n",
    "    dictionary = init_dictionary + diff\n",
    "    dictionary = dictionary / torch.norm(dictionary, p=2, dim=1, keepdim=True)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e86c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_dispersion(dictionary, center, ratio):\n",
    "    new_dictionary = np.zeros(dictionary.shape)\n",
    "    for i in range(dictionary.shape[1]):\n",
    "        vec = dictionary[:,i]\n",
    "        angle = np.arccos(center.T @ vec)\n",
    "        y_vec = vec - (center.T @ vec) * center\n",
    "        y_vec = y_vec / np.linalg.norm(y_vec)\n",
    "        new_dictionary[:,i] = np.cos(ratio * angle) * center + np.sin(ratio * angle) * y_vec\n",
    "    return new_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2ddd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    # build the constructor\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.bn_1 = torch.nn.BatchNorm1d(n_inputs)\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "        self.linear = torch.nn.Linear(n_inputs, n_outputs)\n",
    "\n",
    "    # make predictions\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(self.dropout(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba36103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(dataset_name):\n",
    "    if dataset_name == \"cifar10\":\n",
    "        return LogisticRegression(n_inputs=128, n_outputs=10)\n",
    "\n",
    "    elif dataset_name == \"cifar100\":\n",
    "        return LogisticRegression(n_inputs=824, n_outputs=100)\n",
    "\n",
    "    elif dataset_name == \"cub\":\n",
    "        return LogisticRegression(n_inputs=208, n_outputs=200)\n",
    "\n",
    "    elif dataset_name == \"places365\":\n",
    "        return LogisticRegression(n_inputs=2207, n_outputs=365)\n",
    "\n",
    "    elif dataset_name == \"imagenet\":\n",
    "        return LogisticRegression(n_inputs=4523, n_outputs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc97af51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dictionary = torch.load(f'ip_omp/saved_files/{dataset}_dictionary.pt')\n",
    "dictionary = dictionary.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f6fe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "datay = torch.tensor(\n",
    "    np.load(\n",
    "        f\"ip_omp/saved_files/{dataset}_train_embeddings.npy\",\n",
    "        mmap_mode=\"r\",\n",
    "    )\n",
    ")\n",
    "\n",
    "dataz = np.load(\n",
    "        f\"ip_omp/saved_files/{dataset}_train_labels.npy\",\n",
    "        mmap_mode=\"r\",)\n",
    "\n",
    "datay_test = torch.tensor(\n",
    "    np.load(\n",
    "        f\"ip_omp/saved_files/{dataset}_test_embeddings.npy\",\n",
    "        mmap_mode=\"r\",\n",
    "    )\n",
    ")\n",
    "\n",
    "dataz_test = np.load(\n",
    "        f\"ip_omp/saved_files/{dataset}_test_labels.npy\",\n",
    "        mmap_mode=\"r\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7adf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torch.utils.data.TensorDataset(datay,torch.tensor(dataz))\n",
    "test_ds = torch.utils.data.TensorDataset(datay_test,torch.tensor(dataz_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62124cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "    # Loop through GPUs and print their type\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03413a56",
   "metadata": {},
   "source": [
    "## Constrained Concept Refinement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28beff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atom Dispersion\n",
    "mean = np.mean(dictionary, axis=1)\n",
    "mean = mean / np.linalg.norm(mean)\n",
    "cos_to_mean = mean.T @ dictionary\n",
    "ratio = np.arccos(0)/np.arccos(min(cos_to_mean))\n",
    "new_dictionary = dictionary_dispersion(dictionary, mean, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be18ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 100\n",
    "# Suggested threshold value for each datasets:\n",
    "# CIFAR 10: 0.15\n",
    "# CIFAR 100: 0.215\n",
    "# CUB 200: 0.22\n",
    "# ImageNet: 0.24\n",
    "# Places365: 0.22\n",
    "threshold = 0.15 \n",
    "radius_bound = 0.1\n",
    "d_lr = 1e-4\n",
    "l_lr = 1e0\n",
    "mmtm = 0.9\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model_d = get_model(dataset)\n",
    "model_d.to(device)\n",
    "dictionary_d = torch.tensor(new_dictionary, dtype=torch.float32).to(device)\n",
    "dictionary_d.requires_grad = True\n",
    "ori_dictionary_d = dictionary_d.detach().clone()\n",
    "\n",
    "optimizer_d = torch.optim.SGD([\n",
    "            {'params': model_d.parameters()},\n",
    "            {'params': dictionary_d, 'lr': d_lr}\n",
    "        ], lr=l_lr, momentum=mmtm)\n",
    "\n",
    "hard_thresh = torch.nn.Threshold(threshold,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ad0c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "niter = 20\n",
    "\n",
    "acc_log_d = np.zeros(niter)\n",
    "spr_log_d = np.zeros(niter)\n",
    "avg_log_d = np.zeros(niter)\n",
    "max_log_d = np.zeros(niter)\n",
    "\n",
    "hard_thresh = torch.nn.Threshold(threshold,0)\n",
    "\n",
    "while True:\n",
    "    # Train the model\n",
    "    dataloader = torch.utils.data.DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=1)\n",
    "    model_d.train()\n",
    "    for data in tqdm.tqdm(dataloader):\n",
    "        x, y = data\n",
    "\n",
    "        x = x.to(device)\n",
    "\n",
    "        y = y.to(device).long()\n",
    "\n",
    "        optimizer_d.zero_grad()\n",
    "\n",
    "        coeffs =  x @ dictionary_d\n",
    "        coeffs = hard_thresh(coeffs)\n",
    "\n",
    "        outputs = model_d(coeffs)\n",
    "\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "\n",
    "        optimizer_d.step()\n",
    "        dictionary_d.data = dictionary_project(dictionary_d.data.T, ori_dictionary_d.T, radius_bound).T\n",
    "\n",
    "        \n",
    "    loss = loss.item()\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(test_ds, batch_size=bs, shuffle=False, num_workers=1)\n",
    "    model_d.eval()\n",
    "    correct = 0\n",
    "    sparsity = 0\n",
    "    for data in tqdm.tqdm(dataloader):\n",
    "        x,y = data\n",
    "        x = x.to(device)\n",
    "        y = y.to(device).long()\n",
    "\n",
    "        coeffs =  x @ dictionary_d\n",
    "        coeffs = hard_thresh(coeffs)\n",
    "        sparsity += (torch.abs(coeffs) > 1e-4).sum()\n",
    "        outputs = model_d(coeffs)\n",
    "\n",
    "        predicted = torch.argmax(outputs.data, 1)\n",
    "        correct += (predicted == y).sum()\n",
    "    acc = 100 * (correct.item()) / len(test_ds)\n",
    "    spr =  sparsity.item() / len(test_ds)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        column_norms = torch.norm(dictionary_d - ori_dictionary_d, p=2, dim=0)\n",
    "        average_norm = torch.mean(column_norms)\n",
    "        largest_norm = torch.max(column_norms)\n",
    "    print(\"Epoch:\", ctr, \"Train Loss:\", loss, \"Test accuracy:\", acc)\n",
    "    print(\"Sparsity:\", spr)\n",
    "    print(\"Average column deviation:\",average_norm.cpu().numpy(),\"Maximum column deviation:\",largest_norm.cpu().numpy())\n",
    "    \n",
    "    acc_log_d[ctr] = acc\n",
    "    spr_log_d[ctr] = spr\n",
    "    avg_log_d[ctr] = average_norm\n",
    "    max_log_d[ctr] = largest_norm\n",
    "    ctr += 1\n",
    "\n",
    "    if ctr >= niter:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af70c8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
